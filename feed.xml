<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://rufeng-liu.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://rufeng-liu.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-07-19T02:16:40+00:00</updated><id>https://rufeng-liu.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Sampling Weights</title><link href="https://rufeng-liu.github.io/blog/2024/Sampling-Weights/" rel="alternate" type="text/html" title="Sampling Weights"/><published>2024-07-16T00:00:00+00:00</published><updated>2024-07-16T00:00:00+00:00</updated><id>https://rufeng-liu.github.io/blog/2024/Sampling-Weights</id><content type="html" xml:base="https://rufeng-liu.github.io/blog/2024/Sampling-Weights/"><![CDATA[<h2 id="sampling-weights">Sampling Weights</h2> <p>Construct a base weight for each sampled unit, the reciprocal of its probability of selection into the sample, to correct for their unequal probabilities of selection, e.g, \(w_i=\frac{1}{p_i}\).</p> <p>For multi-stage designs, the base weights must reflect the probabilities of selection at each stage, e.g, \(p_{ij}=p_i\times p_{j(i)}\). Then, base weight \(w_{ij,b}=\frac{1}{p_{ij}}\).</p> <p>The weight for non-response \(w_{ij,nr}\), and the weight for non-coverage is \(w_{ij,nc}\), will be explained later. The overall weight is \(w_{ij}=w_{ij,b}\times w_{ij,nr} \times w_{ij,nc}\).</p> <p>Some units have duplicates on the frame, then increased probability of selection of such units can be compensated. Suppose the \(i\)-th sampled unit has a probability of selections denoted by \(p_{i1},\ldots,p_{ik}\), the adjusted probability of selection of the sampled unit is \(p_i=1-(1-p_{i1})(1-p_{i2})\cdots(1-p_{ik})\), then \(w_i=\frac{1}{p_i}\).</p> <h3 id="for-non-response">For non-response</h3> <p>In a survey, participants may provide no data at all (<code class="language-plaintext highlighter-rouge">total non-response</code>) or only partial data (<code class="language-plaintext highlighter-rouge">item non-response</code>). If there are any systematic differences between the respondents and non-respondents, then naive estimates based solely on the respondents will be biased. The size of the non-response bias for a sample mean, for instance, is a function of two factors: (1) the proportion of the population that does not respond, (2) the size of the difference in population means between respondent and nonrespondent groups. Reducing the bias due to non-response therefore requires that either the non-response rate be small, or that there are small differences between responding and non-responding households and persons.</p> <p>For <code class="language-plaintext highlighter-rouge">total non-response</code>, there are three basic procedures for compensation:</p> <ol> <li>Non-response adjustment of the weights.</li> <li>Drawing a larger sample than needed and creating a reserve sample from which replacements are selected in case of non-response.</li> <li>Substitution, the process of replacing a non-responding participant with another participant that was not sampled which is in close proximity to the non-responding participant with respect to the characteristic of interest.</li> </ol> <h4 id="non-response-adjustment-of-sample-weights">Non-response adjustment of sample weights</h4> <p>The adjustment transfers the base weights of all eligible non-responding sampled units to the responding units.</p> <ol> <li>Apply the initial weights;</li> <li>Partition the sample into subgroups and compute weighted response rates for each subgroup;</li> <li>Use the reciprocal of the subgroup response rates for non-response adjustments;</li> <li>Calculate the non-response adjusted weight for the \(i\)-th unit as \(w_i=w_{1i}\times w_{2i}\), where \(w_{1i}\) is the initial weight and \(w_{2i}\) is the non-response adjustment weight.</li> </ol> <h3 id="for-non-coverage">For non-coverage</h3> <p><code class="language-plaintext highlighter-rouge">Non-coverage</code> refers to the failure of the sampling frame to cover all of the target population and thus some sampling units have no probability of selection into the sample selected for the survey.</p> <p>Several procedures for handling the problem of non-coverage:</p> <ol> <li>Improved field procedures such as the use of multiple frames and improved listing procedures;</li> <li>Compensating for the non-coverage through a statistical adjustment of the weights.</li> </ol> <h2 id="nhanes">NHANES</h2> <p><a href="https://wwwn.cdc.gov/nchs/nhanes/tutorials/weighting.aspx">Weighting in NHANES</a>.</p>]]></content><author><name></name></author><category term="sample"/><category term="methods"/><summary type="html"><![CDATA[Sampling weights]]></summary></entry><entry><title type="html">Horseshoe estimator</title><link href="https://rufeng-liu.github.io/blog/2024/Horseshoe-Estimator/" rel="alternate" type="text/html" title="Horseshoe estimator"/><published>2024-07-09T00:00:00+00:00</published><updated>2024-07-09T00:00:00+00:00</updated><id>https://rufeng-liu.github.io/blog/2024/Horseshoe-Estimator</id><content type="html" xml:base="https://rufeng-liu.github.io/blog/2024/Horseshoe-Estimator/"><![CDATA[<p>Introduction to Horseshoe estimator/prior, comparison versus other priors like spike-and-slab.</p> <h2 id="horseshoe">Horseshoe</h2> <p>Citation <d-cite key="carvalho2010horseshoe"></d-cite></p> <h2 id="properties">Properties</h2> <h2 id="comparison">Comparison</h2> <hr/>]]></content><author><name></name></author><category term="Bayesian-model/variable-selection"/><category term="Horseshoe"/><summary type="html"><![CDATA[Horseshoe for sparsity]]></summary></entry><entry><title type="html">Jackknife, Bootstrap and Bayesian Bootstrap</title><link href="https://rufeng-liu.github.io/blog/2024/Jackknife-Bootstrap-BayesianBootstrap/" rel="alternate" type="text/html" title="Jackknife, Bootstrap and Bayesian Bootstrap"/><published>2024-07-06T00:00:00+00:00</published><updated>2024-07-06T00:00:00+00:00</updated><id>https://rufeng-liu.github.io/blog/2024/Jackknife-Bootstrap-BayesianBootstrap</id><content type="html" xml:base="https://rufeng-liu.github.io/blog/2024/Jackknife-Bootstrap-BayesianBootstrap/"><![CDATA[<p>Ways of resampling, comparison of Jackknife, Bootstrap and Bayesian Bootstrap.</p> <h2 id="jackknife">Jackknife</h2> <p>Citation <d-cite key="miller1974jackknife"></d-cite></p> <p>Given a sample of size \(n\), a <a href="https://en.wikipedia.org/wiki/Jackknife_resampling">jackknife estimator</a> can be built by aggregating the parameter estimates from each subsample of size \((n-1)\) obtained by omitting one observation.</p> <p>Useful for bias and variance estimation, a linear approximation of the bootstrap.</p> <h2 id="bootstrap">Bootstrap</h2> <p>Citation <d-cite key="efron1992bootstrap"></d-cite></p> <p>The <a href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)">bootstrap</a> works by treating inference of the true probability distribution \(J\), given the original data, as being analogous to an inference of the empirical distribution \(\hat{J}\), given the resampled data (using random sampling with replacement). The accuracy of inferences regarding \(\hat{J}\) using the resampled data can be assessed because we know \(\hat{J}\). If \(\hat{J}\) is a reasonable approximation to \(J\), then the quality of inference on \(J\) can in turn be inferred.</p> <p>Suppose we have a sample of size \(n\), \(x_1, \ldots, x_n\), i.i.d. from a random variable/vector \(X\). A statistic \(\hat{\phi}\) is chosen to estimate a parameter \(\phi\) of the distribution of \(X\). The bootstrap distribution of \(\hat{\phi}\) is generated by taking repeated bootstrap replications from \(x_1, \ldots, x_n\). Each replication from \(x_1, \ldots, x_n\) is a random sample of size \(n\) with replacement, and each replication of \(\hat{\phi}\) is the value of \(\hat{\phi}\) calculated on the boostrap replicated sample. The bootstrapped distribution of \(\hat{\phi}\) is generated by considering all possible bootstrap replications of \(\hat{\phi}\).</p> <p>A generalization of the jackknife, useful in estimating the properties of an estimand or constructing hypothesis tests.</p> <p>Pros: straightforward, can be applied to complex sampling designs, control and check the stability.</p> <p>Cons: rely on assumptions (e.g. independence of samples or large enough of a sample size), time-consuming, lead to inconsistency with finite-sample.</p> <h2 id="bayesian-bootstrap">Bayesian Bootstrap</h2> <p>Citation <d-cite key="rubin1981bayesian"></d-cite></p> <p>The <a href="https://en.wikipedia.org/wiki/Bootstrapping_(statistics)#Bayesian_bootstrap">Bayesian bootstrap</a> is analogous to the bootstrap.</p> <p>Each Bayesian bootstrap replication generates a posterior probability for each \(x_i\), where values of \(X\) that are not observed have zero posterior probability, just as they have zero probability under the sample cdf. The posterior probability for each \(x_i\) is centered at \(\frac{1}{n}\) but has variability. The way of generating is like drawing from a \(n-1\) variate Dirichlet distribution with parameter vector \((1, \ldots, 1)\). Specifically, one Bayesian bootstrap replication is generated by drawing \((n - 1)\) uniform \((0, 1)\) random variates \(u_1, \ldots, u_{n-1}\), ordering them, and calculating the gaps \(g_i = u_{(i)}-u_{(i-l)}, i = 1, \ldots, n-1\) where \(u_{(0)} = 0\) and \(u_{(n)} = 1\). Then \(g = (g_1, \ldots, g_n)\) is the vector of probabilities to attach to the data values \(x_1, \ldots, x_n\) in that Bayesian bootstrap replication. Considering all Bayesian bootstrap replications gives the Bayesian bootstrap distribution of the distribution of \(X\) and thus of any parameter of this distribution.</p> <p>The interpretations of the resulting distributions will be different because the Bayesian bootstrap simulates the posterior distribution of the parameter \(\phi\), whereas the bootstrap simulates the estimated sampling distribution of a statistic \(\hat{\phi}\) estimating \(\phi\). The Bayesian bootstrap has an inherent advantage over the bootstrap with respect to the resulting inferences about parameters: the Bayesian bootstrap generates likelihood statements about parameters rather than frequency statements about statistics under assumed values for parameters.</p> <hr/>]]></content><author><name></name></author><category term="Resampling"/><summary type="html"><![CDATA[Bootstrap]]></summary></entry><entry><title type="html">Variational Inference</title><link href="https://rufeng-liu.github.io/blog/2024/Variational-Inference/" rel="alternate" type="text/html" title="Variational Inference"/><published>2024-06-28T00:00:00+00:00</published><updated>2024-06-28T00:00:00+00:00</updated><id>https://rufeng-liu.github.io/blog/2024/Variational-Inference</id><content type="html" xml:base="https://rufeng-liu.github.io/blog/2024/Variational-Inference/"><![CDATA[<p>Use optimization rather than use sampling. First posit a family of densities, then to find a member of that family which is close to the target density. Use exponential family as an example.</p> <h2 id="exponential-families">Exponential families</h2> <p><a href="https://en.wikipedia.org/wiki/Exponential_family">Exponential families</a> include <a href="https://en.wikipedia.org/wiki/Normal_distribution">normal</a>, <a href="https://en.wikipedia.org/wiki/Log-normal_distribution">log-normal</a>, <a href="https://en.wikipedia.org/wiki/Exponential_distribution">exponential</a>, <a href="https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution">inverse Gaussian</a>, <a href="https://en.wikipedia.org/wiki/Gamma_distribution">gamma</a>, <a href="https://en.wikipedia.org/wiki/Chi-squared_distribution">chi-squared</a>, <a href="https://en.wikipedia.org/wiki/Beta_distribution">beta</a>, <a href="https://en.wikipedia.org/wiki/Dirichlet_distribution">Dirichlet</a>, <a href="https://en.wikipedia.org/wiki/Bernoulli_distribution">Bernoulli</a>, <a href="https://en.wikipedia.org/wiki/Categorical_distribution">categorical</a>, <a href="https://en.wikipedia.org/wiki/Poisson_distribution">Poisson</a>, <a href="https://en.wikipedia.org/wiki/Wishart_distribution">Wishart</a>, <a href="https://en.wikipedia.org/wiki/Inverse-Wishart_distribution">inverse Wishart</a>, <a href="https://en.wikipedia.org/wiki/Geometric_distribution">geometric</a>, <a href="https://en.wikipedia.org/wiki/Binomial_distribution">binomial</a>(with fixed number of failures), <a href="https://en.wikipedia.org/wiki/Multinomial_distribution">multinomial</a>(with fixed number of failures), <a href="https://en.wikipedia.org/wiki/Negative_binomial_distribution">negative binomial</a>(with fixed number of failures), <a href="https://en.wikipedia.org/wiki/Weibull_distribution">Weibull</a>(with fixed shape parameter)…</p> <p>For variable \(\boldsymbol{x}=(x_1,\ldots,x_k)^{T}\), a family of distributions with paramter \(\boldsymbol{\theta}\equiv (\theta_1,\ldots,\theta_s)^{T}\) is said to belong to an exponential family if the p.d.f (or p.m.f) can be written as</p> \[f_X(\boldsymbol{X}\mid\boldsymbol{\theta})=h(\boldsymbol{x})\text{exp}\left(\sum_{i=1}^{s} \eta_{i}(\boldsymbol{\theta})T_i(\boldsymbol{x})-A(\boldsymbol{\theta})\right)\] <p>or campactly</p> \[f_X(\boldsymbol{X}\mid\boldsymbol{\theta})=h(\boldsymbol{x})\text{exp}\left(\boldsymbol{\eta}(\boldsymbol{\theta})\cdot T(\boldsymbol{x})-A(\boldsymbol{\theta})\right)\] <p>The dimensions \(k\) of the random variable need not match the dimension \(d\) of the parameter vector, nor (in the case of a curved exponential function) the dimension \(s\) of the natural parameter \(\boldsymbol{\eta}\) and sufficient statistic \(T(\boldsymbol{x})\) .</p> <h2 id="dirichlet-process-and-dirichlet-process-mixture">Dirichlet process and Dirichlet process mixture</h2> <p>Citation <d-cite key="ferguson1973bayesian"></d-cite></p> <p>A <code class="language-plaintext highlighter-rouge">Dirichlet process</code> \(G\) is parameterized by a centering measure \(G_0\) and a positive presicion/scaling parameter \(\alpha\), if for all natural numbers \(k\) and \(k\)-partitions \(\{B_1,\ldots,B_k\}\):</p> \[\left(G(B_1),\ldots,G(B_k)\right)\sim \text{Dir}\left(\alpha G_0(B_1),\ldots,\alpha G_0(B_k)\right).\] <p>Suppose we independently draw \(N\) random variables \(\eta_n\) from \(G\):</p> \[\begin{aligned} G\mid G_0,\alpha &amp;\sim \text{DP}(G_0,\alpha)\\ \eta_n &amp;\sim G, \quad n\in\{1,\ldots,N\}. \end{aligned}\] <p>Conditioning on \(n − 1\) draws, the \(n\)th value is, with positive probability, exactly equal to one of those draws:</p> \[p(\cdot\mid \eta_1,\ldots,\eta_{n-1})\propto \alpha G_0(\cdot)+\sum_{i=1}^{n-1} \delta_{\eta_i}(\cdot).\] <p>Thus, the variables \(\{\eta_1,\ldots,\eta_{n−1}\}\) are randomly partitioned according to which variables are equal to the same value, with the distribution of the partition obtained from a Polya urn scheme.</p> <p>Let \(\{\eta^{*}_{1},\ldots,\eta^{*}_{\lvert \boldsymbol{c} \rvert }\}\) denote the distinct values of \(\{\eta_1,\ldots,\eta _{n-1}\}\), let \(\boldsymbol{c} = \{c_1,...,c_ {n−1}\}\) be assignment variables such that \(\eta_i = \eta^*_ {c_i}\), and let \(\lvert\boldsymbol{c}\rvert\) denote the number of cells in the partition. The distribution of \(\eta_n\) follows the urn distribution:</p> \[\eta_n = \begin{cases} \eta^*_i &amp; \text{with prob.} \frac{|\lbrace j:c_j=i \rbrace|}{n-1+\alpha} \\ \eta, \eta\sim G_0 &amp; \text{with prob.} \frac{\alpha}{n-1+\alpha}, \end{cases}\] <p>where</p> \[|\{j : c_ {j}=i\}|\] <p>is the number of times the value \(\eta^{*}_{i}\) occurs in \(\{\eta_{1},\ldots,\eta_{n−1}\}\).</p> <p>Given Dirichlet process \(G\), a DP mixtures are densities \(p(x)=\int p(x, \eta)d\eta\), or we can have non-i.i.d observations \(x_n\overset{ind}{\sim}p_{n,G}(x)=\int p(x;\eta)dG(\eta)\), in terms of \(N\) latent variables \(\eta_1,\ldots,\eta_N\), the model can be written as</p> \[x_n\mid\eta_n\overset{ind}{\sim}p_n(x_n;\eta_n), \quad \eta_n\mid G\overset{i.i.d}{\sim}G, \quad G\mid G_0,\alpha \sim \text{DP}(G_0,\alpha)\] <p>Given a sample \(\{x_1,\ldots,x_N\}\) from a DP mixture, the predictive density is</p> \[p(x\mid x_1,\ldots,x_N,\alpha,G_0)=\int p(x\mid \eta)p(\eta\mid x_1,\ldots,x_N,\alpha,G_0)d\eta\] <p>which we can use MCMC to achieve posterior draws, together with posterior distribution \(p(\eta\mid x_1,\ldots,x_N,\alpha,G_0)\).</p> <p>The <code class="language-plaintext highlighter-rouge">stick-breaking</code> representation <d-cite key="sethuraman1994constructive"></d-cite> is widely used. Consider two infinite collections of independent random variables, \(V_i\sim\text{Beta}(1,\alpha)\) and \(\eta^*_i\sim G_0\), for \(i=\{1,2,\ldots\}\). The stick-breaking representation of \(G\) is as follows:</p> \[G=\sum_{i=1}^{\infty} \pi_i(\boldsymbol{v})\delta_{\eta^*_i}, \quad \pi_i(\boldsymbol{v})=v_{i} \prod_{j=1}^{i-1}(1-v_j)\] <p>In the DP mixture, the vector \(\pi(\boldsymbol{v})\) comprises the infinite vector of mixing proportions and \(\{\eta^*_1,\eta^*_2,\ldots\}\) are the atoms representing the mixture components. Let \(Z_n\) be an assignment variable of the mixture component with which the data point \(x_n\) is associated. The data can be described as arising from the following process:</p> <ol> <li>Draw \(V_i\sim \text{Beta}(1,\alpha), \quad i=\{1,2,\ldots\}\)</li> <li>Draw \(\eta^*_i\mid G_0\sim G_0, \quad \quad i=\{1,2,\ldots\}\)</li> <li> <p>For the \(n\)th data point:</p> <p>(a) Draw \(Z_n\mid \{v_1,v_2,\ldots\}\sim \text{Mult}(\pi(\boldsymbol{v}))\); (b) Draw \(X_n\mid z_n\sim p(x_n\mid \eta^*_{z_n})\)</p> </li> </ol> <p>Restrict the DP mixtures that the observable data are drawn from an exponential family distribution, and where the base distribution for the DP is the corresponding conjugate prior.</p> <p>The distribution of \(X_n\) conditional on \(Z_n\) and \({\eta^*_1,\eta^*_2,\ldots}\) is:</p> \[p(x_n\mid z_n,\eta^*_1,\eta^*_2,\ldots)=\prod_{i=1}^{\infty} \left(h(x_n) \text{exp} \left\{ {\eta^* _i}^T x_n-a(\eta^*_i) \right\} \right)^{\mathbf{1}\lbrack z_n=i \rbrack}\] <p>where \(a(\eta^*_i)\) is the appropriate cumulant function and we assume for simplicity that \(x\) is the sufficient statistic for the natural parameter \(\eta\).</p> <p>The vector of sufficient statistics of the corresponding conjugate family is \(({\eta^* _i}^T, -a(\eta^*_i) )^T\). The base distribution is:</p> \[p(\eta^*\mid \lambda) = h(\eta^*) \text{exp}\left\{\lambda_1^T \eta^* + \lambda_2 (-a(\eta^*))-a(\lambda)\right\}\] <p>where we decompose the hyperparameter \(\lambda\), such that \(\lambda_1\) contains the first \(\dim(\eta^*)\) components and \(\lambda_2\) is a scalar.</p> <h2 id="inference">Inference</h2> <p>Citation <d-cite key="blei2017variational"></d-cite></p> <h3 id="gibbs-sampling">Gibbs sampling</h3> <p>Review of the collapsed Gibbs sampler and blocked Gibbs sampler for DP mixtures.</p> <h4 id="collapesd-gibbs-sampling">Collapesd Gibbs sampling</h4> <p>The <code class="language-plaintext highlighter-rouge">collapsed Gibbs sampler</code> for a DP mixture with conjugate base distribution integrates out the random measure \(G\) and distinct parameter values \(\{\eta^{*}_{1},\ldots,\eta^{*}_{\lvert \boldsymbol{c} \rvert }\}\). The Markov chain is thus defined only on the latent partition \(\boldsymbol{c} = \{c_1,...,c_ {N}\}\), where \(\lvert\boldsymbol{c}\rvert\) denote the number of cells in the partition. The algorithm iteratively samples each assignment variable \(C_n\), for \(n\in \{1,\ldots,N\}\), conditional on the other cells in the partition, \(\boldsymbol{c_{-n}}\). The assignment \(C_n\) can be one of \(\lvert \boldsymbol{c_{-n}}\rvert +1\) values: either the \(n\)th data point is in a cell with other data points, or in a cell by itself.</p> <p>Exchangeability implies that \(C_n\) has the following multinomial distribution:</p> \[p(c_n=k\mid \boldsymbol{x},\boldsymbol{c}_ {-n},\lambda,\alpha)\propto p(x_n\mid \boldsymbol{x}_ {-n}, \boldsymbol{c}_ {-n}, c_n=k, \lambda)p(c_n=k\mid \boldsymbol{c}_ {-n}, \alpha)\] <p>The first term is a ratio of normalizing constants of the posterior distribution of the \(k\)th parameter, one including and one excluding the \(n\)th data point:</p> \[p(x_n\mid \boldsymbol{x}_ {-n}, \boldsymbol{c}_ {-n}, c_n=k, \lambda)=\frac{\text{exp}\left\{a(\lambda_1+\sum_{m\neq n} \mathbf{1} \lbrack c_m =k \rbrack x_m +x_n, \lambda_2 +\sum_{m\neq n} \mathbf{1} \lbrack c_m =k \rbrack +1)\right\}}{\text{exp}\left\{a(\lambda_1+\sum_{m\neq n} \mathbf{1} \lbrack c_m =k \rbrack x_m, \lambda_2 +\sum_{m\neq n} \mathbf{1} \lbrack c_m =k \rbrack)\right\}}\] <h4 id="blocked-gibbs-sampling">Blocked Gibbs sampling</h4> <h3 id="variational-inference">Variational inference</h3> <h2 id="implementation">Implementation</h2> <p>Citation <d-cite key="blei2017variational"></d-cite> <d-cite key="blei2006variational"></d-cite></p> <hr/>]]></content><author><name></name></author><category term="Optimization"/><category term="Variational"/><category term="Dirichlet-process"/><summary type="html"><![CDATA[Variational Bayesian]]></summary></entry><entry><title type="html">Bayesian Model Selection via MCMC</title><link href="https://rufeng-liu.github.io/blog/2024/Bayesian-Model-Selection-via-MCMC/" rel="alternate" type="text/html" title="Bayesian Model Selection via MCMC"/><published>2024-06-24T00:00:00+00:00</published><updated>2024-06-24T00:00:00+00:00</updated><id>https://rufeng-liu.github.io/blog/2024/Bayesian-Model-Selection-via-MCMC</id><content type="html" xml:base="https://rufeng-liu.github.io/blog/2024/Bayesian-Model-Selection-via-MCMC/"><![CDATA[<h2 id="method">Method</h2> <p>Citation <d-cite key="carlin1995bayesian"></d-cite>.</p> <p>Choose between \(K\) models with corresponding parameter vector \(\boldsymbol{\theta}_j\), \(j=1,...K\).</p> <p>Let \(M\) be an integer-valued parameter that indexes the model, for model \(j\), we have a likelihood \(f(\boldsymbol{y}\mid \boldsymbol{\theta}_j,M=j)\) and a prior \(p(\boldsymbol{\theta}_j\mid M=j)\). Given \(M=j\), \(\boldsymbol{y}\) is independent of \(\{\boldsymbol{\theta_{i\neq j}}\}\). Assume that given the indicator \(M\), \(\boldsymbol{\theta}_j\) are independent of each other, we can complete the Bayesian model specification by choosing proper <code class="language-plaintext highlighter-rouge">pseudopriors</code> \(p(\boldsymbol{\theta}_j\mid M\neq j)\), which is a conveniently chosen linking density. Reason is shown below, let \(\boldsymbol{\theta}=\{\boldsymbol{\theta}_1,\ldots,\boldsymbol{\theta}_K\}\), \(p(\boldsymbol{y} \mid M=j)=\int f(\boldsymbol{y}\mid \boldsymbol{\theta},M=j)p(\boldsymbol{\theta}\mid M=j)d\boldsymbol{\theta}=\int f(\boldsymbol{y}\mid \boldsymbol{\theta}_{j},M=j)p(\boldsymbol{\theta}_{j}\mid M=j)d\boldsymbol{\theta}_j\) Given prior model probabilities \(\pi_{j}\equiv P(M=j)\) such that \(\sum_{j=1}^{K}\pi_{j}=1\), when \(M=j\), the joint distribution of \(\boldsymbol{y}\) and \(\boldsymbol{\theta}\) is</p> \[\begin{aligned} p(\boldsymbol{y},\boldsymbol{\theta},M=j) &amp; = f(\boldsymbol{y}\mid \boldsymbol{\theta},m=j)p(\boldsymbol{\theta}\mid M=j)p(M=j) \\ &amp; = f(\boldsymbol{y}\mid \boldsymbol{\theta}_j,m=j)p(\boldsymbol{\theta}\mid M=j)p(M=j) \\ &amp; = f(\boldsymbol{y}\mid \boldsymbol{\theta}_j,m=j) \left\{\prod_{i=1}^{K} p(\boldsymbol{\theta}_i\mid M=j)\right\} p(M=j)\\ &amp; = f(\boldsymbol{y}\mid \boldsymbol{\theta}_j,m=j) \left\{\prod_{i=1}^{K} p(\boldsymbol{\theta}_i\mid M=j)\right\} \pi_{j} \end{aligned}\] <p>To implement Gibbs sampler the full conditional distributions of each \(\boldsymbol{\theta}_j\) and \(M\). For \(\boldsymbol{\theta}_j\), when \(M=j\), we generate from the usual model \(j\) full conditional; when \(M\neq j\), we generate from the linking function (<code class="language-plaintext highlighter-rouge">pseudoprior</code>).</p> \[p(\boldsymbol{\theta}_j \mid \boldsymbol{\theta}_{i\neq j},M,\boldsymbol{y}) \propto \begin{cases} f(\boldsymbol{y}\mid \boldsymbol{\theta}_j,M=j)p(\boldsymbol{\theta}_j\mid M = j) &amp; M=j, \\ p(\boldsymbol{\theta}_j\mid M\neq j) &amp; M\neq j, \end{cases}\] <p>For discrete finite parameter \(M\):</p> \[p(M=j\mid \boldsymbol{\theta},\boldsymbol{y})=\frac{f(\boldsymbol{y}\mid \boldsymbol{\theta}_j,M=j)\prod_{i=1}^{K} p(\boldsymbol{\theta}_i\mid M=j) \pi_j}{\sum_{k=1}^{K} \left(f(\boldsymbol{y}\mid \boldsymbol{\theta}_k,M=k)\prod_{i=1}^{K} p(\boldsymbol{\theta}_i\mid M=k) \pi_k \right)}\] <p>The algorithm will produce samples from the correct joint posterior distribution. The ratio</p> \[\hat{p}(M=j\mid \boldsymbol{y})=\frac{\text{number of }M^{(g)}=j}{\text{total number of }M^{(g)}},\quad j=1,\ldots,K.\] <p>provides estimates that be used to compute the Bayes factor (ratio of the observed marginal densities for the two models)</p> \[B_{ji}=\frac{p(\boldsymbol{y}\mid M=j)}{p(\boldsymbol{y}\mid M=i)}\] <p>between any two of the models.</p> <hr/> <h2 id="implementation">Implementation</h2> <p>Citation <d-cite key="carlin1995bayesian"></d-cite> <d-cite key="jauch2021mixture"></d-cite>.</p> <p>Poor choices of the linking density (<code class="language-plaintext highlighter-rouge">pseudopriors</code>) \(p(\boldsymbol{\theta}_j\mid M\neq j)\) will make jumps between models extremely unlikely, so that the convergence of the Gibbs sampling may trapped to one model, which might not be the true one in fact. Good choices will produce \(\boldsymbol{\theta}_j^{(g)}\)-values that are consistent with the data, so that \(p(M=j\mid \boldsymbol{\theta},\boldsymbol{y})\) will still be reasonably large at the next \(M\) update step.</p> <p>If for a particular data set one of the \(p(M=j\mid \boldsymbol{y})\) is extremely large, the \(\pi_j\) may be adjusted to correct the imbalance during the early stage of the algorithm, so that the final value of \(B_{ji}\) reflect the true odds in favour of \(M=j\) suggested by the data.</p> <p>Key point: Use the data to help to select the <code class="language-plaintext highlighter-rouge">pseudopriors</code> but <code class="language-plaintext highlighter-rouge">not</code> the prior, match the <code class="language-plaintext highlighter-rouge">pseudopriors</code> as nearly as possible to the true model-specific posteriors.</p> <hr/>]]></content><author><name></name></author><category term="Bayesian-model/variable-selection"/><summary type="html"><![CDATA[Bayesian model selection]]></summary></entry></feed>