<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Bayesian Model Selection via MCMC | Rufeng Liu </title> <meta name="author" content="Rufeng Liu"> <meta name="description" content="Bayesian model selection"> <meta name="keywords" content="Bayesian nonparametric, Model selection, Statistical computing"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/myfavicon.png?b20f02ad5e865d6bb37e8673b87bf49e"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://rufeng-liu.github.io/blog/2024/Bayesian-Model-Selection-via-MCMC/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Bayesian Model Selection via MCMC",
            "description": "Bayesian model selection",
            "published": "June 24, 2024",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Rufeng</span> Liu </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Bayesian Model Selection via MCMC</h1> <p>Bayesian model selection</p> </d-title> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#method">Method</a> </div> <div> <a href="#implementation">Implementation</a> </div> <ul> <li> <a href="#example">Example</a> </li> <li> <a href="#in-project">In project</a> </li> </ul> </nav> </d-contents> <h2 id="method">Method</h2> <p>Citation <d-cite key="carlin1995bayesian"></d-cite>.</p> <p>Choose between \(K\) models with corresponding parameter vector \(\boldsymbol{\theta}_j\), \(j=1,...K\).</p> <p>Let \(M\) be an integer-valued parameter that indexes the model, for model \(j\), we have a likelihood \(f(\boldsymbol{y}\mid \boldsymbol{\theta}_j,M=j)\) and a prior \(p(\boldsymbol{\theta}_j\mid M=j)\). Given \(M=j\), \(\boldsymbol{y}\) is independent of \(\{\boldsymbol{\theta_{i\neq j}}\}\). Assume that given the indicator \(M\), \(\boldsymbol{\theta}_j\) are independent of each other, we can complete the Bayesian model specification by choosing proper <code class="language-plaintext highlighter-rouge">pseudopriors</code> \(p(\boldsymbol{\theta}_j\mid M\neq j)\), which is a conveniently chosen linking density. Reason is shown below, let \(\boldsymbol{\theta}=\{\boldsymbol{\theta}_1,\ldots,\boldsymbol{\theta}_K\}\), \(p(\boldsymbol{y} \mid M=j)=\int f(\boldsymbol{y}\mid \boldsymbol{\theta},M=j)p(\boldsymbol{\theta}\mid M=j)d\boldsymbol{\theta}=\int f(\boldsymbol{y}\mid \boldsymbol{\theta}_{j},M=j)p(\boldsymbol{\theta}_{j}\mid M=j)d\boldsymbol{\theta}_j\) Given prior model probabilities \(\pi_{j}\equiv P(M=j)\) such that \(\sum_{j=1}^{K}\pi_{j}=1\), when \(M=j\), the joint distribution of \(\boldsymbol{y}\) and \(\boldsymbol{\theta}\) is</p> \[\begin{aligned} p(\boldsymbol{y},\boldsymbol{\theta},M=j) &amp; = f(\boldsymbol{y}\mid \boldsymbol{\theta},m=j)p(\boldsymbol{\theta}\mid M=j)p(M=j) \\ &amp; = f(\boldsymbol{y}\mid \boldsymbol{\theta}_j,m=j)p(\boldsymbol{\theta}\mid M=j)p(M=j) \\ &amp; = f(\boldsymbol{y}\mid \boldsymbol{\theta}_j,m=j) \left\{\prod_{i=1}^{K} p(\boldsymbol{\theta}_i\mid M=j)\right\} p(M=j)\\ &amp; = f(\boldsymbol{y}\mid \boldsymbol{\theta}_j,m=j) \left\{\prod_{i=1}^{K} p(\boldsymbol{\theta}_i\mid M=j)\right\} \pi_{j} \end{aligned}\] <p>To implement Gibbs sampler the full conditional distributions of each \(\boldsymbol{\theta}_j\) and \(M\). For \(\boldsymbol{\theta}_j\), when \(M=j\), we generate from the usual model \(j\) full conditional; when \(M\neq j\), we generate from the linking function (<code class="language-plaintext highlighter-rouge">pseudoprior</code>).</p> \[p(\boldsymbol{\theta}_j \mid \boldsymbol{\theta}_{i\neq j},M,\boldsymbol{y}) \propto \begin{cases} f(\boldsymbol{y}\mid \boldsymbol{\theta}_j,M=j)p(\boldsymbol{\theta}_j\mid M = j) &amp; M=j, \\ p(\boldsymbol{\theta}_j\mid M\neq j) &amp; M\neq j, \end{cases}\] <p>For discrete finite parameter \(M\):</p> \[p(M=j\mid \boldsymbol{\theta},\boldsymbol{y})=\frac{f(\boldsymbol{y}\mid \boldsymbol{\theta}_j,M=j)\prod_{i=1}^{K} p(\boldsymbol{\theta}_i\mid M=j) \pi_j}{\sum_{k=1}^{K} \left(f(\boldsymbol{y}\mid \boldsymbol{\theta}_k,M=k)\prod_{i=1}^{K} p(\boldsymbol{\theta}_i\mid M=k) \pi_k \right)}\] <p>The algorithm will produce samples from the correct joint posterior distribution. The ratio</p> \[\hat{p}(M=j\mid \boldsymbol{y})=\frac{\text{number of }M^{(g)}=j}{\text{total number of }M^{(g)}},\quad j=1,\ldots,K.\] <p>provides estimates that be used to compute the Bayes factor (ratio of the observed marginal densities for the two models)</p> \[B_{ji}=\frac{p(\boldsymbol{y}\mid M=j)}{p(\boldsymbol{y}\mid M=i)}\] <p>between any two of the models.</p> <hr> <h2 id="implementation">Implementation</h2> <p>Citation <d-cite key="carlin1995bayesian"></d-cite>.</p> <p>Poor choices of the linking density (<code class="language-plaintext highlighter-rouge">pseudopriors</code>) \(p(\boldsymbol{\theta}_j\mid M\neq j)\) will make jumps between models extremely unlikely, so that the convergence of the Gibbs sampling may trapped to one model, which might not be the true one in fact. Good choices will produce \(\boldsymbol{\theta}_j^{(g)}\)-values that are consistent with the data, so that \(p(M=j\mid \boldsymbol{\theta},\boldsymbol{y})\) will still be reasonably large at the next \(M\) update step.</p> <p>If for a particular data set one of the \(p(M=j\mid \boldsymbol{y})\) is extremely large, the \(\pi_j\) may be adjusted to correct the imbalance during the early stage of the algorithm, so that the final value of \(B_{ji}\) reflect the true odds in favour of \(M=j\) suggested by the data.</p> <p>Key point: Use the data to help to select the <code class="language-plaintext highlighter-rouge">pseudopriors</code> but <code class="language-plaintext highlighter-rouge">not</code> the prior, match the <code class="language-plaintext highlighter-rouge">pseudopriors</code> as nearly as possible to the true model-specific posteriors.</p> <h3 id="example">Example</h3> <p>Citation <d-cite key="jauch2021mixture"></d-cite>.</p> <p>Let $I=(a,b)$ with $a,b\in \mathbf{R}\cup \lbrace -\infty,\infty \rbrace$. Suppose $f$ and $g$ are density functions with $\int_{I}f(x)dx=1$, $\int_{I}g(x)dx=1$, and $g&gt;0$ on $I$, with $F$ and $G$ be the corresponding distribution functions. For each $s\in I$, let $g^s$ denote the truncated density function with $g^s(x)=g(x)\mathbf{1}_ {(-\infty,s]}(x)/G(s)$ for $x\in I$. We say that $F$ is smaller than $G$ in the likelihood ratio order, denote $F\leq_{LR} G$, if $f/g$ is monotone non-increasing. It is shown that, $f/g$ is monotone non-increasing and locally absolutely continuous on $I$ if and only if there exists $\theta \in \lbrack 0,1 \rbrack$ and an absolutely continuous distribution function $U$ with $U(a+)=0$ and $U(b-)=1$ such that $f(x)=\theta g(x) + (1-\theta) \int_{a}^{b} g^{s}(x)U’(s)ds$, $x\in I$. When this mixture representation exists, $\theta=\lim_{x\uparrow b} f(x)/g(x)$, if $\theta\in[0,1)$, $U$ is uniquely determined with $U(x)=\frac{G(x)}{1-\theta}\lbrace \frac{F(x)}{G(x)}-\frac{f(x)}{g(x)} \rbrace$, $x\in I$. Choosing a spike-and-slab prior that assigns positive probability to the event $\theta=1$ enable us to do model selection, using the posterior probability of $H_0: F=G$, equivalent to $\theta=1$, versus $H_1: F\leq_{LR} G$, equivalent to $\theta\in[0,1)$.</p> <h3 id="in-project">In project</h3> <hr> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2024-06-24-Bayesian-Model-Selection-via-MCMC.bib"></d-bibliography> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Rufeng Liu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: August 21, 2024. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>