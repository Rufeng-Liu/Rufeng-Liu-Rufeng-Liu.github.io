<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <p>Use optimization rather than use sampling. First posit a family of densities, then to find a member of that family which is close to the target density. Use exponential family as an example.</p> <h2 id="exponential-families">Exponential families</h2> <p><a href="https://en.wikipedia.org/wiki/Exponential_family" rel="external nofollow noopener" target="_blank">Exponential families</a> include <a href="https://en.wikipedia.org/wiki/Normal_distribution" rel="external nofollow noopener" target="_blank">normal</a>, <a href="https://en.wikipedia.org/wiki/Log-normal_distribution" rel="external nofollow noopener" target="_blank">log-normal</a>, <a href="https://en.wikipedia.org/wiki/Exponential_distribution" rel="external nofollow noopener" target="_blank">exponential</a>, <a href="https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution" rel="external nofollow noopener" target="_blank">inverse Gaussian</a>, <a href="https://en.wikipedia.org/wiki/Gamma_distribution" rel="external nofollow noopener" target="_blank">gamma</a>, <a href="https://en.wikipedia.org/wiki/Chi-squared_distribution" rel="external nofollow noopener" target="_blank">chi-squared</a>, <a href="https://en.wikipedia.org/wiki/Beta_distribution" rel="external nofollow noopener" target="_blank">beta</a>, <a href="https://en.wikipedia.org/wiki/Dirichlet_distribution" rel="external nofollow noopener" target="_blank">Dirichlet</a>, <a href="https://en.wikipedia.org/wiki/Bernoulli_distribution" rel="external nofollow noopener" target="_blank">Bernoulli</a>, <a href="https://en.wikipedia.org/wiki/Categorical_distribution" rel="external nofollow noopener" target="_blank">categorical</a>, <a href="https://en.wikipedia.org/wiki/Poisson_distribution" rel="external nofollow noopener" target="_blank">Poisson</a>, <a href="https://en.wikipedia.org/wiki/Wishart_distribution" rel="external nofollow noopener" target="_blank">Wishart</a>, <a href="https://en.wikipedia.org/wiki/Inverse-Wishart_distribution" rel="external nofollow noopener" target="_blank">inverse Wishart</a>, <a href="https://en.wikipedia.org/wiki/Geometric_distribution" rel="external nofollow noopener" target="_blank">geometric</a>, <a href="https://en.wikipedia.org/wiki/Binomial_distribution" rel="external nofollow noopener" target="_blank">binomial</a>(with fixed number of failures), <a href="https://en.wikipedia.org/wiki/Multinomial_distribution" rel="external nofollow noopener" target="_blank">multinomial</a>(with fixed number of failures), <a href="https://en.wikipedia.org/wiki/Negative_binomial_distribution" rel="external nofollow noopener" target="_blank">negative binomial</a>(with fixed number of failures), <a href="https://en.wikipedia.org/wiki/Weibull_distribution" rel="external nofollow noopener" target="_blank">Weibull</a>(with fixed shape parameter)…</p> <p>For variable \(\boldsymbol{x}=(x_1,\ldots,x_k)^{T}\), a family of distributions with paramter \(\boldsymbol{\theta}\equiv (\theta_1,\ldots,\theta_s)^{T}\) is said to belong to an exponential family if the p.d.f (or p.m.f) can be written as</p> \[f_X(\boldsymbol{X}\mid\boldsymbol{\theta})=h(\boldsymbol{x})\text{exp}\left(\sum_{i=1}^{s} \eta_{i}(\boldsymbol{\theta})T_i(\boldsymbol{x})-A(\boldsymbol{\theta})\right)\] <p>or campactly</p> \[f_X(\boldsymbol{X}\mid\boldsymbol{\theta})=h(\boldsymbol{x})\text{exp}\left(\boldsymbol{\eta}(\boldsymbol{\theta})\cdot T(\boldsymbol{x})-A(\boldsymbol{\theta})\right)\] <p>The dimensions \(k\) of the random variable need not match the dimension \(d\) of the parameter vector, nor (in the case of a curved exponential function) the dimension \(s\) of the natural parameter \(\boldsymbol{\eta}\) and sufficient statistic \(T(\boldsymbol{x})\) .</p> <h2 id="dirichlet-process-and-dirichlet-process-mixture">Dirichlet process and Dirichlet process mixture</h2> <p>Citation <d-cite key="ferguson1973bayesian"></d-cite></p> <p>A Dirichlet process \(G\) is parameterized by a centering measure \(G_0\) and a positive presicion/scaling parameter \(\alpha\), if for all natural numbers \(k\) and \(k\)-partitions \(\{B_1,\ldots,B_k\}\):</p> \[\left(G(B_1),\ldots,G(B_k)\right)\sim \text{Dir}\left(\alpha G_0(B_1),\ldots,\alpha G_0(B_k)\right).\] <p>Suppose we independently draw \(N\) random variables \(\eta_n\) from \(G\):</p> \[\begin{aligned} G\mid G_0,\alpha &amp;\sim \text{DP}(G_0,\alpha)\\ \eta_n &amp;\sim G, \quad n\in\{1,\ldots,N\}. \end{aligned}\] <p>Conditioning on \(n − 1\) draws, the \(n\)th value is, with positive probability, exactly equal to one of those draws:</p> \[p(\cdot\mid \eta_1,\ldots,\eta_{n-1})\propto \alpha G_0(\cdot)+\sum_{i=1}^{n-1} \delta_{\eta_i}(\cdot).\] <p>Thus, the variables \(\{\eta_1,\ldots,\eta_{n−1}\}\) are randomly partitioned according to which variables are equal to the same value, with the distribution of the partition obtained from a Polya urn scheme.</p> <p>Let \(\{\eta^{*}_{1},\ldots,\eta^{*}_{\lvert \boldsymbol{c} \rvert }\}\) denote the distinct values of \(\{\eta_1,\ldots,\eta _{n-1}\}\), let \(\boldsymbol{c} = \{c_1,...,c_ {n−1}\}\) be assignment variables such that \(\eta_i = \eta^*_ {c_i}\), and let \(\lvert\boldsymbol{c}\rvert\) denote the number of cells in the partition. The distribution of \(\eta_n\) follows the urn distribution:</p> \[\eta_n = \begin{cases} \eta^*_i &amp; \text{with prob.} \frac{|\lbrace j:c_j=i \rbrace|}{n-1+\alpha} \\ \eta, \eta\sim G_0 &amp; \text{with prob.} \frac{\alpha}{n-1+\alpha}, \end{cases}\] <p>where</p> \[|\{j : c_ {j}=i\}|\] <p>is the number of times the value \(\eta^{*}_{i}\) occurs in \(\{\eta_{1},\ldots,\eta_{n−1}\}\).</p> <p>Given Dirichlet process \(G\), a DP mixtures are densities \(p(x)=\int p(x, \eta)d\eta\), or we can have non-i.i.d observations \(x_n\overset{ind}{\sim}p_{n,G}(x)=\int p(x;\eta)dG(\eta)\), in terms of \(N\) latent variables \(\eta_1,\ldots,\eta_N\), the model can be written as</p> \[x_n\mid\eta_n\overset{ind}{\sim}p_n(x_n;\eta_n), \quad \eta_n\mid G\overset{i.i.d}{\sim}G, \quad G\mid G_0,\alpha \sim \text{DP}(G_0,\alpha)\] <p>Given a sample \(\{x_1,\ldots,x_N\}\) from a DP mixture, the predictive density is</p> \[p(x\mid x_1,\ldots,x_N,\alpha,G_0)=\int p(x\mid \eta)p(\eta\mid x_1,\ldots,x_N,\alpha,G_0)d\eta\] <p>which we can use MCMC to achieve posterior draws, together with posterior distribution \(p(\eta\mid x_1,\ldots,x_N,\alpha,G_0)\).</p> <p>The stick-breaking representation <d-cite key="sethuraman1994constructive"></d-cite> is widely used. Consider two infinite collections of independent random variables, \(V_i\sim\text{Beta}(1,\alpha)\) and \(\eta^*_i\sim G_0\), for \(i=\{1,2,\ldots\}\). The stick-breaking representation of \(G\) is as follows:</p> \[G=\sum_{i=1}^{\infty} \pi_i(\boldsymbol{v})\delta_{\eta^*_i}, \quad \pi_i(\boldsymbol{v})=v_{i} \prod_{j=1}^{i-1}(1-v_j)\] <p>In the DP mixture, the vector \(\pi(\boldsymbol{v})\) comprises the infinite vector of mixing proportions and \(\{\eta^*_1,\eta^*_2,\ldots\}\) are the atoms representing the mixture components. Let \(Z_n\) be an assignment variable of the mixture component with which the data point \(x_n\) is associated. The data can be described as arising from the following process:</p> <ol> <li>Draw \(V_i\sim \text{Beta}(1,\alpha), \quad i=\{1,2,\ldots\}\)</li> <li>Draw \(\eta^*_i\mid G_0\sim G_0, \quad \quad i=\{1,2,\ldots\}\)</li> <li> <p>For the \(n\)th data point:</p> <p>(a) Draw \(Z_n\mid \{v_1,v_2,\ldots\}\sim \text{Mult}(\pi(\boldsymbol{v}))\); (b) Draw \(X_n\mid z_n\sim p(x_n\mid \eta^*_{z_n})\)</p> </li> </ol> <p>Restrict the DP mixtures that the observable data are drawn from an exponential family distribution, and where the base distribution for the DP is the corresponding conjugate prior.</p> <p>The distribution of \(X_n\) conditional on \(Z_n\) and \({\eta^*_1,\eta^*_2,\ldots}\) is:</p> \[p(x_n\mid z_n,\eta^*_1,\eta^*_2,\ldots)=\prod_{i=1}^{\infty} \left(h(x_n) \text{exp} \left\{ {\eta^* _i}^T x_n-a(\eta^*_i) \right\} \right)^{\mathbf{1}\lbrack z_n=i \rbrack}\] <p>where \(a(\eta^*_i)\) is the appropriate cumulant function and we assume for simplicity that \(x\) is the sufficient statistic for the natural parameter \(\eta\).</p> <p>The vector of sufficient statistics of the corresponding conjugate family is \(({\eta^* _i}^T, -a(\eta^*_i) )^T\). The base distribution is:</p> \[p(\eta^*\mid \lambda) = h(\eta^*) \text{exp}\left\{\lambda_1^T \eta^* + \lambda_2 (-a(\eta^*))-a(\lambda)\right\}\] <p>where we decompose the hyperparameter \(\lambda\), such that \(\lambda_1\) contains the first \(\dim(\eta^*)\) components and \(\lambda_2\) is a scalar.</p> <h2 id="inference">Inference</h2> <p>Citation <d-cite key="blei2017variational"></d-cite></p> <h3 id="gibbs-sampling">Gibbs sampling</h3> <h4 id="collapesd-gibbs-sampling">Collapesd Gibbs sampling</h4> <h4 id="blocked-gibbs-sampling">Blocked Gibbs sampling</h4> <h3 id="variational-inference">Variational inference</h3> <h2 id="implementation">Implementation</h2> <p>Citation <d-cite key="blei2017variational"></d-cite> <d-cite key="blei2006variational"></d-cite></p> <hr> </body></html>